{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[//]: # (Copyright c 2021, Alessandro Abate, Daniele Ahmed, Alec Edwards, Mirco Giacobbe, Andrea Peruffo)\n",
    "[//]: # (All rights reserved.)\n",
    "[//]: # (This source code is licensed under the BSD-style license found in the)\n",
    "[//]: # (LICENSE file in the root directory of this source tree. )\n",
    "\n",
    "# ðŸ¦– Welcome to FOSSIL!\n",
    "                                                         ___._\n",
    "                                                       .'  <0>'-.._\n",
    "                                                      /  /.--.____\")\n",
    "                                                     |   \\   __.-'~\n",
    "                                                     |  :  -'/\n",
    "                                                    /:.  :.-'\n",
    "    __________                                     | : '. |\n",
    "    '--.____  '--------.______       _.----.-----./      :/\n",
    "            '--.__            `'----/       '-.      __ :/\n",
    "                  '-.___           :           \\   .'  )/\n",
    "                        '---._           _.-'   ] /  _/\n",
    "                             '-._      _/     _/ / _/\n",
    "                                 \\_ .-'____.-'__< |  \\___\n",
    "                                   <_______.\\    \\_\\_---.7\n",
    "                                  |   /'=r_.-'     _\\\\ =/\n",
    "                              .--'   /            ._/'>\n",
    "                            .'   _.-'\n",
    "                           / .--'\n",
    "                          /,/\n",
    "                          |/`)\n",
    "                          'c=,\n",
    "\n",
    "## Overview\n",
    "\n",
    "This tool uses neural networks alongside the CEGIS architecture to automatically synthesise sound Lyapunov functions of Barrier Certificates for any N-dimensional system.\n",
    "\n",
    "This notebook provides access to the following settings:\n",
    "\n",
    "1. ### [Verifier Type](#verifier-type)\n",
    "1. ### [Neural Network Structure](#nn-structure) \n",
    "    i)  Activation functions \\\n",
    "    ii) Layer structure (number of neurons, number of layers)\n",
    "1. ### [Factorisation](#factorisation)\n",
    "1. ### [Last Layer of Ones](#ll1)\n",
    "1. ### [Barrier Function Sythesis Settings](#barrier-settings)\n",
    "1. ### [Sympy Settings](#sympy-settings)\n",
    "1. ### [Further CEGIS Settings](#further-settings) \n",
    "    i)   Learning Rate \\\n",
    "    ii)  Batch size \\\n",
    "    iii) Maximum number of CEGIS iterations \\\n",
    "    iv)  Rounding \n",
    "1. ### [Primer Settings](#primer-settings)\n",
    "    i)   Seed and Speed \\\n",
    "    ii)  Positive Domain \\\n",
    "    iii)  Interactive Domain \n",
    "\n",
    "    \n",
    "### [Running the tool with custom settings](#running)\n",
    "\n",
    "### [Advanced Functionality](#advanced)\n",
    "If you would like to use a more simple interface to the tool with just defualt settings, please use the [playground](FOSSIL-playground.ipynb).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# % Imports\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from experiments.playground_utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='verifier-type'></a>\n",
    "## 1. Verifier Type\n",
    "#### (*CegisConfig.VERIFIER.k*)\n",
    "\n",
    "The tool has inbuilt support for both Z3 and Dreal4, and either can be selected as the backend to the verification. Please note that certain functionality cannot be used with Z3 as the verifier, though this is the default verifier.\n",
    "\n",
    "**To specify the verifier, change the following variable to either VerifierType.Z3 or VerifierType.DREAL**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verifier_type = VerifierType.Z3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='nn-structure'></a>\n",
    "## 2. Neural Network Structure\n",
    "\n",
    "### Activations\n",
    "#### (*CegisConfig.ACTIVATION.k*)\n",
    "The following activation functions are available:\n",
    "\n",
    "* ### Linear or identity:\n",
    "$$\\sigma(x) = x $$\n",
    "___\n",
    "\n",
    "* ### Square:\n",
    "$$\\sigma(x) = x^2 $$\n",
    "___\n",
    "\n",
    "* ### Mixed $n^{th}$ order Polynomial:\n",
    "$$ \\sigma(x) = \\sum_{i=1}^{n}x_i ^i, $$ where $x_i$ represents the i^th neurons in the layer, giving a mixed layer of activations. For more details on this please see [mixed_activation_functions]\n",
    "___\n",
    "\n",
    "* ### RELU:\n",
    "$$ \\sigma(x) = \\max(0,x) $$\n",
    "___\n",
    "\n",
    "* ### RELU-Square:\n",
    "$$\\sigma(x) = x_1^2 + \\max(0, x_2), $$\n",
    "\n",
    "where x_1 denotes the the first half of the neurons in the layer and x_2 denotes the second half. \n",
    "___\n",
    "\n",
    "* ### REQU:\n",
    "$$ \\sigma(x) = x \\cdot \\max(0,x)$$\n",
    "___\n",
    "\n",
    "* ### Sigmoid (requires Dreal):\n",
    "$$ \\sigma(x) = \\frac{\\text{e}^{x}}{\\text{e}^{x} +1}$$\n",
    "___\n",
    "\n",
    "* ### Tanh (requires Dreal):\n",
    "$$\\sigma(x) = \\tanh(x) $$\n",
    "\n",
    "\n",
    "### Neuron Structure\n",
    "####  (*CegisConfig.N_HIDDEN_NEURONS.k*)\n",
    "The tool supports any number of layers each with any number of neurons and activation function. However, it should be noted that larger networks will have longer verification times. \n",
    "\n",
    "The desired activation functions for each should be inlcuded as a list with each element representing the activation function for that layer. Similarly, the number of neurons in each layer should be inlcuded as a list.\n",
    "For example, for a network structure with two hidden layers, one with 50 and one with 20 neurons, the first of which has mixed second-order polynomial (LIN_SQUARE)  activations and the second with relu (RELU) activations.\n",
    "\n",
    "activations = \\[ ActivationType.LIN_SQUARE, ActivationType.RELU \\] \n",
    "\n",
    "neurons     = \\[ 50, 20 \\]\n",
    "\n",
    "The default parameters are given in the cell below and can be changed freely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activations = [ActivationType.SQUARE]\n",
    "neurons = [10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='factorisation'></a>\n",
    "## 3. Factorisation \n",
    "#### (*CegisConfig.FACTORS.k*)\n",
    "\n",
    "In order to help ensure that $V(x^*) = 0$ when synthesising Lyapunov r functions, the learner can be augmented with a quadratic term as $$ V(x) = (x-x^*)^2 \\cdot \\text{n}(x), $$  where $n(x)$ is the original neural network.  <!---For more details on the factorisation please see [factorisation](../tex/factorisation.tex).--->\n",
    "\n",
    "**To use quadratic factors, set the following variable to LearningFactors.QUADRATIC.** \\\n",
    "**To not use any factors (the defualt setting), set the following variable to None**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "factors = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Last Layer of Ones (Lyapunov Only)\n",
    "\n",
    "#### (*CegisConfig.LLO.k*)\n",
    "llo(*boolean, defualt True*): This constrains the last layer of the neural network to be all ones. This can improve synthesise by helping ensure the positive definiteness (V(x) > 0) condition holds for the learner and verifier.\n",
    "\n",
    "**To constrain the last layer to be all ones, set the following variable to True.**\n",
    "\n",
    "<a id='ll1'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llo = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='barrier-settings'></a>\n",
    "## 5. Symmetric Belt (Barrier Only)\n",
    "\n",
    "#### (*CegisConfig.SYMMETRIC_BELT.k*)\n",
    "*symmetric_belt (boolean, default=False)*: defines whether the belt for the derivative barrier condition is symmetric around zero (if so, we consider $|B(x)| \\leq 0.5$) or not (if so, the we consider $B(x) \\geq -0.1$). \n",
    "\n",
    "**To constrain the belt to be symmetric, set the following variable to True.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "symmetric_belt = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Sympy Settings\n",
    "<a id='sympy-settings'></a>\n",
    "\n",
    "These settings determine the usage of sympy within the CEGIS object.\n",
    "\n",
    "sp_handle (*boolean, default True*): determines whether expressions are handled using the python symbolic library *sympy*.\n",
    "#### (*CegisConfig.SP_HANDLE.k*)\n",
    "sp_simplify (*boolean, default True*): determines whether expressions are simplified using the *sympy* (potentially costly operation).\n",
    "\n",
    "#### (*CegisConfig.SP_SIMPLIFY.k*)\n",
    "**To disable sympy handling and simplification, set the following variables to False.** \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp_handle = True\n",
    "\n",
    "sp_simplify = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Further CEGIS Settings\n",
    "<a id='further-settings'></a>\n",
    "* Learning Rate (*positive float, default = 0.1*): sets the learning rate of the neural network.\n",
    "#### (*CegisConfig.LEARNING_RATE.k*)\n",
    "\n",
    "\n",
    "* Batch Size (*int, defualt = 500*): defines the number of data points initially generated.\n",
    "#### (*CegisConfig.BATCH_SIZE*)\n",
    "\n",
    "\n",
    "* Max Iterations (*int, default = 10*): sets the maximum number of CEGIS loops before termination.\n",
    "#### (*CegisConfig.CEGIS_MAX_ITERS.k*)\n",
    "\n",
    "\n",
    "* Rounding (*int, default = 3*): sets the rounding precision used in the Translator.\n",
    "#### (*CegisConfig.ROUNDING.k*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.1\n",
    "\n",
    "batch_size = 500\n",
    "\n",
    "max_iterations = 10\n",
    "\n",
    "rounding = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='primer-settings'></a>\n",
    "### 8. Primer Settings\n",
    "\n",
    "These settings affect how CEGIS is called and interacted with.\n",
    "\n",
    "* Seed and Speed (*boolean, default=False*): if *Seed and Speed* is True, then a CEGIS object is repeatedly instantiated on a short timeout until the procedure is successful.\n",
    "#### (*CegisConfig.SEED_AND_SPEED.k*)\n",
    "\n",
    "\n",
    "\n",
    "* Interactive Domain (*boolean, default=False*) : determines whether the user can adjust the domain size if CEGIS fails. Cannot be used in conjunction with *Seed and Speed*.\n",
    "#### (*CegisConfig.INTERACTIVE_DOMAIN.k*)\n",
    "\n",
    "\n",
    "* Positive Domain (*boolean, defualt=False*): Lyapunov only. If True, then the verification domain for Lyapunov conditions is constrained to the positive orthant.\n",
    "#### (*CegisConfig.POSITIVE_DOMAIN.k*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_and_speed = False\n",
    "\n",
    "positive_domain = False\n",
    "\n",
    "domain_mode = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running with custom settings\n",
    "\n",
    "Once you have set custom settings using the cells above, use the following cell to instantiate a dynamical system and to synthesise either a Lyapunov or Barrier Certificate. The settings are placed into the Cegis_Parameters dictionary as shown.\n",
    "<a id='running'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_Dimensions = 2\n",
    "\n",
    "x0, x1 = initialise_states(N_Dimensions)\n",
    "\n",
    "dynamics = [\n",
    "    -x0 + x0 * x1,\n",
    "    -x1\n",
    "]\n",
    "\n",
    "mode = PrimerMode.LYAPUNOV\n",
    "\n",
    "parameters = {CegisConfig.VERIFIER.k: verifier_type,         CegisConfig.ACTIVATION.k: activations,\n",
    "              CegisConfig.N_HIDDEN_NEURONS.k: neurons,       CegisConfig.FACTORS.k: factors, \n",
    "              CegisConfig.LLO.k: llo,                        CegisConfig.LEARNING_RATE.k: learning_rate, \n",
    "              CegisConfig.BATCH_SIZE.k: batch_size,          CegisConfig.CEGIS_MAX_ITERS.k: max_iterations,\n",
    "              CegisConfig.SP_HANDLE.k: sp_handle,            CegisConfig.SP_SIMPLIFY.k: sp_simplify, \n",
    "              CegisConfig.SEED_AND_SPEED.k: seed_and_speed,  CegisConfig.POSITIVE_DOMAIN.k: positive_domain,\n",
    "              CegisConfig.INTERACTIVE_DOMAIN.k: domain_mode,}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_n, f_s = synthesise(dynamics, mode, \n",
    "           CEGIS_PARAMETERS=parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='advanced'></a>\n",
    "## Advanced Functionality\n",
    "\n",
    "Users are able to define custom systems (dynamics + domains) for either Lyapunov synthesis or Barrier synthesis. These should be in the form of the python functions shown below, including routines for generating the system dynamics, symbolic domains and data generation in the domains. Note that for Lyapunov synthesis, the equilibrium point to perform analysis on must lie at the origin.\n",
    "\n",
    "For generating data within domains, users are encouraged to user the existing functions in experiments/benchmarks/domains_fcns.py when possible.\n",
    "\n",
    "These functions can be passed to *synthesise* or to *Primer.create_Primer* as the argument f. In this case, the CegisConfig.N_VARS parameter must be passed in cegis_parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from experiments.benchmarks.domain_fcns import *\n",
    "\n",
    "#Lyapunov Example\n",
    "def lyap_hybrid(batch_size, functions, inner, outer):\n",
    "    # example of 2-d hybrid sys\n",
    "    _And = functions['And']\n",
    "\n",
    "    def f(functions, v):\n",
    "        _If = functions['If']\n",
    "        x0, x1 = v\n",
    "        _then = - x1 - 0.5*x0**3\n",
    "        _else = - x1 - x0**2 - 0.25*x1**3\n",
    "        _cond = x1 >= 0\n",
    "        return [-x0, _If(_cond, _then, _else)]\n",
    "\n",
    "    def XD(_, v):\n",
    "        x0, x1 = v\n",
    "        return _And(inner**2 < x0**2 + x1**2,\n",
    "                               x0**2 + x1**2 <= outer**2)\n",
    "\n",
    "    def SD():\n",
    "        return circle_init_data((0., 0.), outer**2, batch_size)\n",
    "\n",
    "    return f, XD, SD()\n",
    "\n",
    "# Barrier Example\n",
    "def obstacle_avoidance(batch_size, functions):\n",
    "    _And = functions['And']\n",
    "    velo = 1\n",
    "\n",
    "    def f(functions, v):\n",
    "        x, y, phi = v\n",
    "        return [\n",
    "            velo * functions['sin'](phi), velo * functions['cos'](phi),\n",
    "            - functions['sin'](phi) + 3 * (x * functions['sin'](phi) + y * functions['cos'](phi)) / (0.5 + x ** 2 + y ** 2)\n",
    "        ]\n",
    "\n",
    "    def XD(_, v):\n",
    "        x, y, phi = v\n",
    "        return _And(-2 <= x, y <= 2, -1.57 <= phi, phi <= 1.57)\n",
    "\n",
    "    def XI(_, v):\n",
    "        x, y, phi = v\n",
    "        return _And(-0.1 <= x, x <= 0.1, -2 <= y, y <= -1.8, -0.52 <= phi, phi <= 0.52)\n",
    "\n",
    "    def XU(_, v):\n",
    "        x, y, _phi = v\n",
    "        return x**2 + y**2 <= 0.04\n",
    "\n",
    "    def SD():\n",
    "        x_comp = -2 + torch.randn(batch_size, 1)**2\n",
    "        y_comp = 2 - torch.randn(batch_size, 1)**2\n",
    "        phi_comp = segment([-1.57, 1.57], batch_size)\n",
    "        dom = torch.cat([x_comp, y_comp, phi_comp], dim=1)\n",
    "        return dom\n",
    "\n",
    "    def SI():\n",
    "        x = segment([-0.1, 0.1], batch_size)\n",
    "        y = segment([-2.0, -1.8], batch_size)\n",
    "        phi = segment([-0.52, 0.52], batch_size)\n",
    "        return torch.cat([x, y, phi], dim=1)\n",
    "\n",
    "    def SU():\n",
    "        xy = circle_init_data((0., 0.), 0.04, batch_size)\n",
    "        phi = segment([-0.52, 0.52], batch_size)\n",
    "        return torch.cat([xy, phi], dim=1)\n",
    "\n",
    "    bounds = inf_bounds_n(2)\n",
    "    pi = math.pi\n",
    "    bounds.append([-pi/2, pi/2])\n",
    "    return f, XD, XI, XU, SD(), SI(), SU(), bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
