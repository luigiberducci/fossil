{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Welcome to FOSSIL!\n",
    "Overview\n",
    "\n",
    "This tool uses neural networks alongside the powerful CEGIS architecture to automatically synthesise sound Lyapunov functions of Barrier Certificates for any N-dimensional system.\n",
    "\n",
    "\n",
    "This notebook provides access to the following settings:\n",
    "\n",
    "1. ### [Verifier Type](#verifier-type)\n",
    "1. ### [Neural Network Structure](#nn-structure) \n",
    "    i)  Activation functions \\\n",
    "    ii) Layer structure (number of neurons, number of layers)\n",
    "1. ### [Factorisation](#factorisation)\n",
    "1. ### [Last Layer of Ones](#ll1)\n",
    "1. ### [Barrier Function Sythesis Settings](#barrier-settings)\n",
    "1. ### [Sympy Settings](#sympy-settings)\n",
    "1. ### [Further CEGIS Settings](#further-settings) \\\n",
    "    i)   Learning Rate \\\n",
    "    ii)  Batch size \\\n",
    "    iii) Maximum number of CEGIS iterations \\\n",
    "    iv)  Rounding \\\n",
    "1. ### [Primer Settings](#primer-settings)\n",
    "    \n",
    "    \n",
    "### [Running the tool with custom settings](#running)\n",
    "\n",
    "If you would like to use a more simple interface to the tool with just defualt settings, please use the [playground](FOSSIL-playground.ipynb).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# % Imports\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from experiments.playground_utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='verifier-type'></a>\n",
    "## 1. Verifier Type\n",
    "\n",
    "The tool has inbuilt support for both Z3 and Dreal4, and either can be selected as the backend to the verification. Please note that certain functionality cannot be used with Z3 as the verifier, though this is the default verifier.\n",
    "\n",
    "**To specify the verifier, change the following variable to either VerifierType.Z3 or VerifierType.DREAL**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "verifier_type = VerifierType.Z3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='nn-structure'></a>\n",
    "## 2. Neural Network Structure\n",
    "\n",
    "The following activation functions are available:\n",
    "\n",
    "* ### Linear or identity:\n",
    "$$\\sigma(x) = x $$\n",
    "___\n",
    "\n",
    "* ### Square:\n",
    "$$\\sigma(x) = x^2 $$\n",
    "___\n",
    "\n",
    "* ### Mixed $n^{th}$ order Polynomial:\n",
    "$$ \\sigma(x) = \\sum_{i=1}^{n}x_i ^i, $$ where $x_i$ represents the i^th neurons in the layer, giving a mixed layer of activations. For more details on this please see [mixed_activation_functions]\n",
    "___\n",
    "\n",
    "* ### RELU:\n",
    "$$ \\sigma(x) = \\max(0,x) $$\n",
    "___\n",
    "\n",
    "* ### RELU-Square:\n",
    "$$\\sigma(x) = x_1^2 + \\max(0, x_2), $$\n",
    "\n",
    "where x_1 denotes the the first half of the neurons in the layer and x_2 denotes the second half. \n",
    "___\n",
    "\n",
    "* ### REQU:\n",
    "$$ \\sigma(x) = x \\cdot \\max(0,x)$$\n",
    "___\n",
    "\n",
    "* ### Sigmoid (requires Dreal):\n",
    "$$ \\sigma(x) = \\frac{\\text{e}^{x}}{\\text{e}^{x} +1}$$\n",
    "___\n",
    "\n",
    "* ### Tanh (requires Dreal):\n",
    "$$\\sigma(x) = \\tanh(x) $$\n",
    "\n",
    "\n",
    "### Neuron Structure\n",
    "\n",
    "The tool supports any number of layers each with any number of neurons and activation function. However, it should be noted that larger networks will have longer verification times. \n",
    "\n",
    "The desired activation functions for each should be inlcuded as a list with each element representing the activation function for that layer. Similarly, the number of neurons in each layer should be inlcuded as a list.\n",
    "For example, for a network structure with two hidden layers, one with 50 and one with 20 neurons, the first of which has mixed second-order polynomial (LIN_SQUARE)  activations and the second with relu (RELU) activations.\n",
    "\n",
    "activations = \\[ ActivationType.LIN_SQUARE, ActivationType.RELU \\] \n",
    "\n",
    "neurons     = \\[ 50, 20 \\]\n",
    "\n",
    "The default parameters are given in the cell below and can be changed freely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "activations = [ActivationType.SQUARE]\n",
    "neurons = [10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='factorisation'></a>\n",
    "## 3. Factorisation\n",
    "\n",
    "In order to help ensure that $V(x^*) = 0$ when synthesising Lyapunov r functions, the learner can be augmented such that the template form becomes $$ V(x) = (x-x^*) \\cdot \\text{n}(x)  $$ where $n(x)$ is the original neural network. Alternatively, a quadratic term can be used as $$ V(x) = (x-x^*)^2 \\cdot \\text{n}(x). $$ For more details on the factorisation please see [factorisation](../tex/factorisation.tex).\n",
    "\n",
    "**To use linear factors, set the following variable to 'lf'.** \\\n",
    "**To use quadratic factors, set the following variable to 'qf'.** \\\n",
    "**To not use any factors (the defualt setting), set the following variable to None**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "factors = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Last Layer of Ones (Lyapunov Only)\n",
    "llo(*boolean, defualt True*): This constrains the last layer of the neural network to be all ones. This can improve synthesise by helping ensure the positive definiteness (V(x) > 0) condition holds for the learner and verifier.\n",
    "\n",
    "**To constrain the last layer to be all ones, set the following variable to True.**\n",
    "\n",
    "<a id='ll1'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "llo = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='barrier-settings'></a>\n",
    "## 5. Symettric Belt (Barrier Only)\n",
    "*symmetric_belt (boolean, default=False)*: defines whether the belt for the derivative barrier condition is symmetric around zero (if so, we consider $|B(x)| \\leq 0.5$) or not (if so, the we consider $B(x) \\geq -0.1$). \n",
    "\n",
    "**To constrain the belt to be symmetric, set the following variable to True.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "symmetric_belt = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Sympy Settings\n",
    "<a id='sympy-settings'></a>\n",
    "\n",
    "These settings determine the usage of sympy within the CEGIS object.\n",
    "\n",
    "sp_handle (*boolean, default True*): determines whether expressions are handled using the python symbolic library *sympy*.\n",
    "\n",
    "sp_simplify (*boolean, default True*): determines whether expressions are simplified using the *sympy* (potentially costly operation).\n",
    "\n",
    "**To disable sympy handling and simplification, set the following variables to False.** \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp_handle = True\n",
    "\n",
    "sp_simplify = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Further CEGIS Settings\n",
    "<a id='further-settings'></a>\n",
    "* Learning Rate (*positive float, default = 0.1*): sets the learning rate of the neural network.\n",
    "\n",
    "\n",
    "* Batch Size (*int, defualt = 500*): defines the number of data points initially generated.\n",
    "\n",
    "\n",
    "* Max Iterations (*int, default = 10*): sets the maximum number of CEGIS loops before termination\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.1\n",
    "\n",
    "batch_size = 500\n",
    "\n",
    "max_iterations = 10\n",
    "\n",
    "rounding = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='primer-settings'></a>\n",
    "### 8. Primer Settings\n",
    "\n",
    "These settings affect how CEGIS is called and interacted with.\n",
    "\n",
    "*seedbomb (boolean, default=False)*: if *seedbomb* is True, then a CEGIS object is repeatedly instantiated on a short timeout until the procedure is successful.\n",
    "\n",
    "*interactive_domain (boolean, defualt=False)* : determines whether the user can adjust the domain size if CEGIS fails. Cannot be used in conjunction with *seedbomb*.\n",
    "\n",
    "*positive_domain (boolean, defualt=True)*: Lyapunov only. If True, then the verification domain for Lyapunov conditions is constrained to the positive orthant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "seedbomb = False\n",
    "positive_domain = True\n",
    "domain_mode = 'auto'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running with custom settings\n",
    "\n",
    "Once you have set custom settings using the cells above, use the following cell to instantiate a dynamical system and to synthesise either a Lyapunov or Barrier Certificate.\n",
    "<a id='running'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_Dimensions = 2\n",
    "\n",
    "x0, x1 = initialise_states(N_Dimensions)\n",
    "\n",
    "dynamics = [\n",
    "    -x0 + x0 * x1,\n",
    "    -x1\n",
    "]\n",
    "\n",
    "mode = 'l'  # Change to 'b' to synthesise Barrier Certificate\n",
    "\n",
    "parameters = {'VERIFIER':verifier_type, 'ACTIVATIONS': activations, 'NEURONS':neurons, 'FACTORS':factors, \n",
    "              'LLO':llo, 'LEARNING_RATE':learning_rate, 'BATCH_SIZE':batch_size, 'CEGIS_MAX_ITERS':max_iterations,\n",
    "             'SP_HANDLE': sp_handle, 'SP_SIMPLIFY':sp_simplify,}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single Equilibrium point found: \n",
      " [(0, 0)]\n",
      "Single Equilibrium point found: \n",
      " [(0, 0)]\n",
      "================================================================================\n",
      "  learner   0\n",
      "================================================================================\n",
      "0 - loss: 33.802921295166016 - acc: 69.0 %\n",
      "================================================================================\n",
      "  regulariser   0\n",
      "================================================================================\n",
      "================================================================================\n",
      "  verifier   0\n",
      "================================================================================\n",
      "Counterexample Found: [x1 = 3/2, x0 = 79/8]\n",
      "V(ctx) =  15400235397555439910666729578303037079/640000000000000000000000000000000000\n",
      "Vdot(ctx) =  109178249478152431487993683395259119/640000000000000000000000000000000000\n",
      "================================================================================\n",
      "  trajectoriser   0\n",
      "================================================================================\n",
      "================================================================================\n",
      "  learner   1\n",
      "================================================================================\n",
      "0 - loss: 0.00886671245098114 - acc: 95.80152671755725 %\n",
      "================================================================================\n",
      "  regulariser   1\n",
      "================================================================================\n",
      "================================================================================\n",
      "  verifier   1\n",
      "================================================================================\n",
      "Counterexample Found: [x1 = 25/16, x0 = 79/8]\n",
      "V(ctx) =  34755430180381895120713762519103366191/640000000000000000000000000000000000\n",
      "Vdot(ctx) =  412952633412137125205139435161780961/1280000000000000000000000000000000000\n",
      "================================================================================\n",
      "  trajectoriser   1\n",
      "================================================================================\n",
      "================================================================================\n",
      "  learner   2\n",
      "================================================================================\n",
      "0 - loss: 32184.734375 - acc: 95.8029197080292 %\n",
      "100 - loss: 37.25857925415039 - acc: 77.18978102189782 %\n",
      "200 - loss: 28.834341049194336 - acc: 77.18978102189782 %\n",
      "300 - loss: 21.89669418334961 - acc: 77.55474452554745 %\n",
      "400 - loss: 16.398984909057617 - acc: 78.46715328467154 %\n",
      "500 - loss: 12.170783042907715 - acc: 79.37956204379562 %\n",
      "600 - loss: 8.969298362731934 - acc: 80.1094890510949 %\n",
      "700 - loss: 6.578042984008789 - acc: 81.38686131386861 %\n",
      "800 - loss: 4.784741401672363 - acc: 81.93430656934306 %\n",
      "900 - loss: 3.429306745529175 - acc: 83.21167883211679 %\n",
      "999 - loss: 2.4545111656188965 - acc: 84.12408759124088 %\n",
      "================================================================================\n",
      "  regulariser   2\n",
      "================================================================================\n",
      "================================================================================\n",
      "  verifier   2\n",
      "================================================================================\n",
      "Counterexample Found: [x1 = 1/2, x0 = 2]\n",
      "V(ctx) =  1089982087426672173379615574376663/8000000000000000000000000000000000\n",
      "Vdot(ctx) =  422290070972404252323182980762773/20000000000000000000000000000000000\n",
      "================================================================================\n",
      "  trajectoriser   2\n",
      "================================================================================\n",
      "================================================================================\n",
      "  learner   3\n",
      "================================================================================\n",
      "0 - loss: 2.320052146911621 - acc: 81.14186851211073 %\n",
      "100 - loss: 1.6692253351211548 - acc: 82.69896193771626 %\n",
      "200 - loss: 1.2082476615905762 - acc: 86.67820069204153 %\n",
      "300 - loss: 0.8643190860748291 - acc: 87.19723183391004 %\n",
      "400 - loss: 0.6147457957267761 - acc: 87.71626297577855 %\n",
      "500 - loss: 0.4312971830368042 - acc: 88.06228373702422 %\n",
      "600 - loss: 0.2968592047691345 - acc: 88.75432525951557 %\n",
      "700 - loss: 0.2003130465745926 - acc: 89.10034602076125 %\n",
      "800 - loss: 0.13124185800552368 - acc: 89.7923875432526 %\n",
      "900 - loss: 0.08244743943214417 - acc: 89.96539792387543 %\n",
      "999 - loss: 0.047067105770111084 - acc: 90.48442906574394 %\n",
      "================================================================================\n",
      "  regulariser   3\n",
      "================================================================================\n",
      "================================================================================\n",
      "  verifier   3\n",
      "================================================================================\n",
      "Counterexample Found: [x1 = 1, x0 = 6]\n",
      "V(ctx) =  114593001572758298758485393022454573/1000000000000000000000000000000000000\n",
      "Vdot(ctx) =  11784996885955246406834541853243099/500000000000000000000000000000000000\n",
      "================================================================================\n",
      "  trajectoriser   3\n",
      "================================================================================\n",
      "================================================================================\n",
      "  learner   4\n",
      "================================================================================\n",
      "0 - loss: 0.04449435696005821 - acc: 86.93548387096774 %\n",
      "================================================================================\n",
      "  learner   0\n",
      "================================================================================\n",
      "0 - loss: 88.82111358642578 - acc: 57.8 %\n",
      "================================================================================\n",
      "  regulariser   0\n",
      "================================================================================\n",
      "================================================================================\n",
      "  verifier   0\n",
      "================================================================================\n",
      "No counterexamples found!\n",
      "Found a Lyapunov function\n",
      "================================================================================\n",
      "  trajectoriser   0\n",
      "================================================================================\n",
      "Found a Lyapunov function\n",
      "Learner times: total=14.774213833999966s,min=0.0342640750004648s,max=7.403431338999326s,avg=2.954842766799993s\n",
      "Regulariser times: total=0.05275779800103919s,min=0.010131652000382019s,max=0.010901949000071909s,avg=0.010551559600207839s\n",
      "Verifier times: total=0.09067836200028978s,min=0.015097810000042955s,max=0.02158316500026558s,avg=0.018135672400057957s\n",
      "Trajectoriser times: total=0.02384329899905424s,min=0.002201673999479681s,max=0.013451079999867943s,avg=0.00596082474976356s\n",
      "\n",
      " Attempt to simplify and print the synthesised function? y/n: \n",
      " n\n"
     ]
    }
   ],
   "source": [
    "synthesise(dynamics, mode, SEEDBOMB=seedbomb, POSITIVE_DOMAIN=positive_domain, DOMAIN_MODE=domain_mode,\n",
    "           CEGIS_PARAMETERS=parameters)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lnn",
   "language": "python",
   "name": "lnn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
